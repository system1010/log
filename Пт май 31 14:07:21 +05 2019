diff --git a/init/main.c b/init/main.c
index 66a196c5e4c3..eba0d2393d37 100644
--- a/init/main.c
+++ b/init/main.c
@@ -108,6 +108,10 @@ static int kernel_init(void *);
 extern void init_IRQ(void);
 extern void radix_tree_init(void);
 
+void start(void);
+int thread_function(void *data);
+
+
 /*
  * Debug helper: via this flag we know that we are in 'early bootup code'
  * where only the boot processor is running with IRQ disabled.  This means
@@ -447,6 +451,9 @@ noinline void __ref rest_init(void)
 	 * at least once to get things moving:
 	 */
 	schedule_preempt_disabled();
+	
+	start();
+	
 	/* Call into cpu_idle with preempt disabled */
 	cpu_startup_entry(CPUHP_ONLINE);
 }
diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index f35930f5e528..16af05b9f1bd 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -24,6 +24,201 @@
 
 #include <trace/events/sched.h>
 
+void visit(struct rb_node *node);
+
+
+void printInorder(struct rb_node* node)
+{
+      if (node == NULL)
+       return;
+       /* first recur on left child */
+       printInorder(node->rb_left);
+      /* then print the data of node */
+       visit (node); 
+       /* now recur on right child */
+       printInorder(node->rb_right);
+}
+void printPostorder(struct rb_node* node)
+{
+       if (node == NULL)
+           return;
+
+       // first recur on left subtree
+         printPostorder(node->rb_left);
+       // then recur on right subtree
+         printPostorder(node->rb_right);
+        // now deal with the node
+        visit(node);
+}
+                                       
+void printPreorder(struct rb_node* node)
+{
+        if (node == NULL)
+        return;
+
+	/* first print data of node */
+	visit (node); 
+        /* then recur on left sutree */
+        printPreorder(node->rb_left); 
+        /* now recur on right subtree */
+        printPreorder(node->rb_right);
+} 
+
+
+struct Stack
+{
+	int top;
+	unsigned capacity;
+	struct rb_node* array[100];
+};
+
+struct Stack* createStack(unsigned capacity)
+	{
+		struct Stack* stack = (struct Stack*) kmalloc(sizeof(struct Stack),GFP_KERNEL);
+		stack->capacity = capacity;
+		stack->top = 0;
+		//stack->array[] = (struct rb_node*) kmalloc(stack->capacity * sizeof(struct rb_node), GFP_KERNEL);
+		return stack;
+	}
+	void push(struct Stack* stack, struct rb_node* item)
+	{
+	//if (isFull(stack))
+	//return;
+	stack->array[++stack->top] = item;
+	//printf("%c pushed to stackn", item->data);
+	}
+	struct rb_node* pop(struct Stack* stack)
+	{
+	//if (isEmpty(stack))
+	//return INT_MIN;
+	return stack->array[stack->top--];
+	}
+		//int isFull(struct Stack* stack)
+		//{ return stack->top == stack->capacity - 1; }
+		//int isEmpty(struct Stack* stack)
+		//{ return stack->top == -1; }
+		
+	
+	
+	
+	
+	
+	static struct task_struct *task;
+	static int data = 0x55; 
+	int i;
+	struct rq_flags rf;     
+	int thread_function(void *data){
+	unsigned long tm = jiffies + msecs_to_jiffies(1000);
+	struct rq *rq = task_rq(task);
+	for(;;){
+		if ((long)((jiffies) - (tm)) > 0){
+		tm = jiffies + msecs_to_jiffies(1000);
+		i++;
+		if (i>20) kthread_stop(task);
+		//inOrder
+		rq_lock(rq, &rf);		
+		struct rb_node *node=NULL;
+		for (node = rb_first(&rq->cfs.tasks_timeline.rb_root); node; node = rb_next(node)) visit(node);
+		rq_unlock_irq(rq, &rf);
+	//task_current(cpu_rq(1),task);
+/*
+struct Stack* stack = createStack(100);
+
+struct rb_node* P=rq->cfs.tasks_timeline.rb_root.rb_node;
+
+while(1){
+        if(P){
+       		push(stack, P);
+       		//visit(P);
+       		P=P->rb_left;
+       		continue;
+        }else if (stack->top){
+        //printf("%cn", P->data);
+        //if (P->right!=NULL)printf("%cn", P->right->data);
+        //if (P->right==NULL && P->left==NULL && stack->top>=0)break;
+        //if (stack->top==-1)goto label2;
+        P=pop(stack);
+        //while(P->left!=NULL){
+   	visit(P);
+	//      if(stack->top==-1)break;
+	//      P=pop(stack);
+	//      x=1;
+	//}       
+	//if (x=1){
+		P=P->rb_right;
+		//x=-1;
+	//}
+	continue;
+}
+break;
+}   
+
+	
+		//printPreorder(rq->cfs.tasks_timeline.rb_root.rb_node);
+		//printInorder(rq->cfs.tasks_timeline.rb_root.rb_node);
+	  	//printPostorder(rq->cfs.tasks_timeline.rb_root.rb_node);	 
+*/	
+		printk("0rq->nr_running rq->cfs.nr_running : %li %li\n",rq->nr_running, rq->cfs.nr_running);
+		printk(KERN_NOTICE "0rq->load.weight, rq->cfs.load.weight : %li %li", rq->load.weight, rq->cfs.load.weight);
+//rq_unlock_irq(rq, &rf);
+		
+		/*		//rq=cpu_rq(1);
+		//printk("1rq->nr_running rq->cfs.nr_running : %li %li\n",rq->nr_running, rq->cfs.nr_running);
+		//printk(KERN_NOTICE "1rq->load.weight, rq->cfs.load.weight : %li %li", rq->load.weight, rq->cfs.load.weight);
+		
+P=rq->cfs.tasks_timeline.rb_root.rb_node;
+while(1){
+        if(P){
+	        push(stack, P);
+	        //visit(P);
+	        P=P->rb_left;
+	        continue;
+	}else if (stack->top){
+	//printf("%cn", P->data);
+	//if (P->right!=NULL)printf("%cn", P->right->data);
+	//if (P->right==NULL && P->left==NULL && stack->top>=0)break;
+	//if (stack->top==-1)goto label2;
+		P=pop(stack);
+		//while(P->left!=NULL){
+		visit(P);
+		//      if(stack->top==-1)break;
+		//      P=pop(stack);
+		//      x=1;
+		//}       
+		//if (x=1){
+		P=P->rb_right;
+		//x=-1;
+		//}
+		continue;
+	}
+	break;
+}   
+	
+		
+		
+		
+		rq=cpu_rq(0);
+
+	*/
+//rq_unlock_irq(rq, &rf);
+		printk("----------------------------------------------");
+
+
+
+
+	}else schedule();
+}
+return 0;
+}
+void  start(void) {task = kthread_run(&thread_function,(void *)data,"THREAD");}
+
+void visit(struct rb_node *node){
+//visit node
+struct sched_entity *entry = rb_entry(node, struct sched_entity, run_node);
+struct task_struct *tsk = container_of(entry,struct task_struct, se);
+printk("color, tsk->comm, weight, vruntime: %ld %s %ld %lld", node->__rb_parent_color, tsk->comm, entry->load.weight, entry->vruntime);
+}
+
 /*
  * Targeted preemption latency for CPU-bound tasks:
  *
